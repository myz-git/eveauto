import os
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import pyautogui
import cv2
import numpy as np
import time
import sys
import logging

# 日志配置
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('task.log', mode='a'),
        logging.StreamHandler()
    ],
    force=True
)

# 调试截图目录
DEBUG_DIR = "debug_screenshots"
if not os.path.exists(DEBUG_DIR):
    os.makedirs(DEBUG_DIR)

class IconCNN(nn.Module):
    def __init__(self, icon_height=64, icon_width=64):
        super(IconCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        pooled_height = icon_height // 8
        pooled_width = icon_width // 8
        self.fc1 = nn.Linear(128 * pooled_height * pooled_width, 256)
        self.fc2 = nn.Linear(256, 2)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.6)
        self.bn1 = nn.BatchNorm2d(32)
        self.bn2 = nn.BatchNorm2d(64)
        self.bn3 = nn.BatchNorm2d(128)

    def forward(self, x):
        x = self.pool(self.relu(self.bn1(self.conv1(x))))
        x = self.pool(self.relu(self.bn2(self.conv2(x))))
        x = self.pool(self.relu(self.bn3(self.conv3(x))))
        x = x.view(x.size(0), -1)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

def capture_screen():
    """捕获屏幕截图并转换为OpenCV格式"""
    time.sleep(0.5)  # 等待界面稳定
    screenshot = pyautogui.screenshot()
    screen_image = np.array(screenshot)
    screen_image = cv2.cvtColor(screen_image, cv2.COLOR_RGB2BGR)
    return screen_image

def save_debug_image(image, name):
    """保存调试图像"""
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    path = os.path.join(DEBUG_DIR, f"{timestamp}_{name}.png")
    cv2.imwrite(path, image)
    logging.info(f"Saved debug image: {path}")

def verify_icon(icon_name, max_attempts=3, template_threshold=0.85, model_threshold=0.80):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = IconCNN(icon_height=64, icon_width=64).to(device)
    model_path = os.path.join('model_cnn', f"{icon_name}_classifier.pth")
    
    try:
        model.load_state_dict(torch.load(model_path))
    except FileNotFoundError:
        logging.error(f"Model file {model_path} not found. Please ensure the model file exists.")
        sys.exit(1)
    except RuntimeError as e:
        logging.error(f"Error loading model: {e}")
        print(f"Error loading model: {e}")
        print("The model may have a different structure. Please retrain using 'train.py'.")
        sys.exit(1)
    
    model.eval()
    
    transform = transforms.Compose([
        transforms.Resize((64, 64)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    
    template_path = os.path.join('icon', f"{icon_name}-1.png")
    template = cv2.imread(template_path, cv2.IMREAD_COLOR)
    if template is None:
        logging.error(f"Template image {template_path} not found")
        sys.exit(1)
    
    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)
    w, h = template_gray.shape[::-1]
    
    for attempt in range(max_attempts):
        screen_image = capture_screen()
        save_debug_image(screen_image, f"screen_attempt_{attempt}")
        screen_gray = cv2.cvtColor(screen_image, cv2.COLOR_BGR2GRAY)
        
        res = cv2.matchTemplate(screen_gray, template_gray, cv2.TM_CCOEFF_NORMED)
        max_val = np.max(res)
        logging.info(f"Attempt {attempt+1}: Template matching max_val = {max_val}")
        
        loc = np.where(res >= template_threshold)
        matches = list(zip(*loc[::-1]))
        
        if matches:
            for pt in matches:
                top_left = pt
                bottom_right = (top_left[0] + w, top_left[1] + h)
                icon_image = screen_image[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]
                save_debug_image(icon_image, f"icon_attempt_{attempt}_{pt}")
                icon_rgb = cv2.cvtColor(icon_image, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(icon_rgb)
                tensor = transform(pil_image).unsqueeze(0).to(device)
                
                with torch.no_grad():
                    output = model(tensor)
                    probabilities = torch.softmax(output, dim=1)
                    confidence, predicted = torch.max(probabilities, 1)
                    logging.info(f"Model confidence: {confidence.item()}, predicted: {predicted.item()}")
                    if predicted.item() == 1 and confidence.item() > model_threshold:
                        x = top_left[0] + w // 2
                        y = top_left[1] + h // 2
                        logging.info(f"找到 {icon_name} 坐标: ({x}, {y})")
                        try:
                            pyautogui.moveTo(x, y)
                            cv2.imshow(f"Detected {icon_name}", icon_image)
                            cv2.waitKey(0)
                            cv2.destroyAllWindows()
                        except Exception as e:
                            logging.error(f"Failed to display image or move mouse: {e}")
                        return (x, y)
            logging.info(f"Attempt {attempt+1}: Icon {icon_name} not detected in matched regions")
        else:
            logging.info(f"Attempt {attempt+1}: No matches found for {icon_name}")
    
    return False

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python verify.py jump1")
        sys.exit(1)
    
    icon_name = sys.argv[1]
    try:
        result = verify_icon(icon_name)
        if result:
            print(f"Icon {icon_name} verified successfully")
        else:
            print(f"Icon {icon_name} not verified")
    except Exception as e:
        logging.error(f"Verification failed: {e}")
        sys.exit(1)